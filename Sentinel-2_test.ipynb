{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\eo_data\\Ibague\n",
      "['data', 'S1_GRD', 'S2_L1C']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# change the working directory to the location of files\n",
    "os.chdir('D:/eo_data/Ibague/')\n",
    "print(os.getcwd())\n",
    "# store the files list to a variable\n",
    "eo_files = os.listdir(os.getcwd())\n",
    "print(eo_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip files\n",
    "import zipfile\n",
    "\n",
    "# Check if a data folder exist\n",
    "#if not os.path.exists('data'):\n",
    "#    os.makedirs('data')\n",
    "#    print 'data folder' + ' was created'\n",
    "# Check if the name of the data folder is in\n",
    "#if 'data' in eo_files:\n",
    "#    eo_files.remove('data')\n",
    "##TODO catch error when a directory is in eo_files\n",
    "\n",
    "def unzipfiles(path):\n",
    "    \"\"\"\n",
    "    Unzips every zipfile in the path, and stores in same directory\n",
    "    Args:\n",
    "        path (string): string of directory where zipfiles are located \n",
    "    \"\"\"\n",
    "    for im_id in os.listdir(path):\n",
    "        if not os.path.exists('data/'+im_id[:-3]+'SAFE'):\n",
    "            print('Unzipping ' + im_id)\n",
    "            zip_ref = zipfile.ZipFile(path+im_id, 'r')\n",
    "            zip_ref.extractall('data')\n",
    "            zip_ref.close()\n",
    "        else:\n",
    "            print(im_id[:-4] + ' was already uncompressed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_ref = zipfile.ZipFile('/home/azalazar/data/test_l2A.zip', 'r')\n",
    "zip_ref.extractall('/home/azalazar/data/')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process L1C to L2A images using sen2cor\n",
    "Call in console. To-do: check integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "\n",
    "## TODO: remove hard coding of sen2cor installation\n",
    "def sen2cor_L2A (res, prod): # \n",
    "    \"\"\"\n",
    "    Function to call sen2cor L2A_Process for obtaining L2A products\n",
    "    \n",
    "    res (str/num): resolution, accepts 10, 20, 60, or all \n",
    "    prod (str): location of S1 L1C product\n",
    "    \"\"\"\n",
    "    # Hard-code location of sen2cor installation\n",
    "    os.chdir(\"/home/azalazar/DL_Temp/Sen2Cor-02.05.05-Linux64/bin\")\n",
    "    # Coerce resolution to string\n",
    "    res = str(res)\n",
    "    # Execute L2A_Process with resolution parameter when specified\n",
    "    if res == 'all':\n",
    "        os.system(\"bash L2A_Process\" + \" \" + prod)\n",
    "    else:\n",
    "        os.system(\"bash L2A_Process --resolution=\" + res + \" \" + str(prod))\n",
    "\n",
    "def sen2cor_L2A_batch (res, L1Cdir):\n",
    "    \"\"\"\n",
    "    Function to batch processing of S1-L1C files in a directory to S1-L2A\n",
    "    \n",
    "    res (str/num): resolution, accepts 10, 20, 60, or all\n",
    "    L1Cdir (str): location of S1 L1C products\n",
    "    \"\"\"\n",
    "    # Put S1 L1C directory names in list\n",
    "    L1C_files = filter(re.compile(r'^S2.....L1C').search, os.listdir(L1Cdir))\n",
    "    print(\"{} L1C files found in directory\".format(str(len(L1C_files))))\n",
    "    \n",
    "    for L1C_file in L1C_files: # Iterate over directory names\n",
    "        # Call sen2cor function for individual product\n",
    "        print(\"Processing {}\".format(L1C_file))\n",
    "        sen2cor_L2A(res, L1Cdir+L1C_file)\n",
    "        \n",
    "## Based on:     \n",
    "## Rodrigo Almeida, Maya Situnayake, Kees Baake, Mortimer Werther, Timon Weitkamp, Arnan Araza. Wageningen University.\n",
    "## Academic Consultancy Project for EagleSensing. Remote Sensing and GIS Integration course, Period 6, 2016-2017.\n",
    "## https://github.com/rodrigoalmeida94/ACT_EagleSensing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/azalazar/GitHub/ciat_monitor_crops\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/home/azalazar/data/\"\n",
    "print(os.getcwd())\n",
    "\n",
    "#sen2cor_L2A_batch('all', server_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process L2A images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import snappy\n",
    "import re\n",
    "\n",
    "from sentinelsat.sentinel import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from snappy import ProductIO\n",
    "from snappy import HashMap\n",
    "import shutil\n",
    "import os  \n",
    "import ast\n",
    "\n",
    "from snappy import GPF\n",
    "\n",
    "GPF.getDefaultInstance().getOperatorSpiRegistry().loadOperatorSpis()\n",
    "HashMap = snappy.jpy.get_type('java.util.HashMap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S2A_MSIL2A_20171210T152631_N0206_R025_T18NVK_20171210T170838.SAFE']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set location of products\n",
    "data_dir = \"/home/azalazar/data/\"\n",
    "\n",
    "# get geoJSON file with region extent\n",
    "regName = \"Ibague\"\n",
    "regPath = \"/mnt/workspace_cluster_6/TRANSVERSAL_PROJECTS/MADR/COMPONENTE_2/Imagenes_Satelitales/Sentinel_2/\" + \\\n",
    "                      \"JSON_Ibague/IbagueJSON.geojson\"\n",
    "geom = geojson_to_wkt(read_geojson(regPath))\n",
    "\n",
    "# get a list location of S2 L2A products\n",
    "\n",
    "prdlist = filter(re.compile(r'^S2.....L2A').search, os.listdir(data_dir))\n",
    "#prdlist = map(lambda x: data_dir+x, prdlist)\n",
    "\n",
    "list(prdlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-processing of Sentinel-2 L2A products\n",
    "\n",
    "def preSentinel2(L2Alist, subregion, regname):\n",
    "    \"\"\"\n",
    "    \n",
    "    L2Alist (list): list of location of directory of L2A products (.SAFE dir)\n",
    "    subregion (str): wkt string of extent of region of interest\n",
    "    regname (str): string identifier of the region of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a dictionary to read Sentinel-1 L1 GRD products\n",
    "    product = {}\n",
    "    for element in L2Alist:\n",
    "        product[element[:-5]] = {}\n",
    "        print(element)\n",
    "    \n",
    "    for key, value in product.iteritems():    \n",
    "        # Read the product\n",
    "        print('Reading {}'.format(key+'.SAFE/MTD_MSIL2A.xml'))\n",
    "        value['GRD'] = ProductIO.readProduct(key+'.SAFE/MTD_MSIL2A.xml')\n",
    "        \n",
    "        # Resample all bands to 10m resolution\n",
    "        resample_subset = HashMap()\n",
    "        #resample_subset.put('targetResolution', 10)\n",
    "        print('Resampling {}'.format(key))\n",
    "        #value['res10'] = GPF.createProduct('Resample', resample_subset, value['GRD'])\n",
    "        \n",
    "        # Subset to area of interest\n",
    "        param_subset = HashMap()\n",
    "        param_subset.put('geoRegion', subregion)\n",
    "        param_subset.put('outputImageScaleInDb', False)\n",
    "        param_subset.put('sourceBandNames', 'B2, B3, B4, B8, B11, B12,\\\n",
    "        quality_cloud_confidence,quality_scene_classification')\n",
    "        print('Subsetting {}'.format(key))\n",
    "        #value['sub'] = GPF.createProduct(\"Subset\", param_subset, value['res10'])\n",
    "        \n",
    "        # Write product\n",
    "        print('Writing {} subset resampled to 10m'.format(key))\n",
    "        ProductIO.writeProduct(value['GRD'], key+'_'+regname+'_subset', 'BEAM-DIMAP')\n",
    "        \n",
    "        # Dispose all the intermediate products\n",
    "        value['GRD'].dispose()\n",
    "        #value['res10'].dispose()\n",
    "        #value['sub'].dispose()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2A_MSIL2A_20171210T152631_N0206_R025_T18NVK_20171210T170838.SAFE\n",
      "Reading S2A_MSIL2A_20171210T152631_N0206_R025_T18NVK_20171210T170838.SAFE/MTD_MSIL2A.xml\n",
      "Resampling S2A_MSIL2A_20171210T152631_N0206_R025_T18NVK_20171210T170838\n",
      "Subsetting S2A_MSIL2A_20171210T152631_N0206_R025_T18NVK_20171210T170838\n",
      "Writing S2A_MSIL2A_20171210T152631_N0206_R025_T18NVK_20171210T170838 subset resampled to 10m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "java.lang.IllegalArgumentException: [product] is null",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-294304097a8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreSentinel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprdlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ambiguous Java method call, too many matching method overloads found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# todo test if data is corrupted or there is an installation problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-5638a9813874>\u001b[0m in \u001b[0;36mpreSentinel2\u001b[0;34m(L2Alist, subregion, regname)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Write product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Writing {} subset resampled to 10m'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mProductIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteProduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GRD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mregname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_subset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BEAM-DIMAP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Dispose all the intermediate products\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: java.lang.IllegalArgumentException: [product] is null"
     ]
    }
   ],
   "source": [
    "preSentinel2(prdlist, geom, regName)\n",
    "\n",
    "# ambiguous Java method call, too many matching method overloads found\n",
    "# todo test if data is corrupted or there is an installation problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading D:/eo_data/Ibague/data/test.data/B1.img\n",
      "Reading D:/eo_data/Ibague/data/prep/VH_specklefil_dB.dim\n",
      "Reading D:/eo_data/Ibague/data/prep/VV_specklefil_dB.dim\n",
      "Creating stack...\n",
      "Saving resulting product...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from snappy import ProductIO, GPF, jpy\n",
    "\n",
    "GPF.getDefaultInstance().getOperatorSpiRegistry().loadOperatorSpis()\n",
    "HashMap = jpy.get_type('java.util.HashMap')\n",
    "\n",
    "#collection of preprocessed files\n",
    "s1 = 'D:/eo_data/Ibague/data/prep/VH_specklefil_dB.dim'\n",
    "s2 = 'D:/eo_data/Ibague/data/prep/VV_specklefil_dB.dim'\n",
    "master = 'D:/eo_data/Ibague/data/test.data/B1.img'\n",
    "\n",
    "processed_files = [master,s1,s2]\n",
    "\n",
    "product_set=[]\n",
    "\n",
    "for f in processed_files:\n",
    "    product_set.append(ProductIO.readProduct(f))\n",
    "    print(\"Reading \"+f)\n",
    "      \n",
    "#define the stack parameters\n",
    "params = HashMap()\n",
    "params.put('resamplingType', 'NEAREST_NEIGHBOUR')\n",
    "params.put('initialOffsetMethod', 'Product Geolocation')\n",
    "params.put('extent', 'Master')\n",
    "\n",
    "#make the stack\n",
    "print(\"Creating stack...\")\n",
    "create_stack = GPF.createProduct('CreateStack', params, product_set)\n",
    "\n",
    "#write the stack\n",
    "print(\"Saving resulting product...\")\n",
    "ProductIO.writeProduct(create_stack, 'D:/eo_data/Ibague/data/create_stack', 'BEAM-DIMAP')\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
