{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentinel-1 data download using sentinelsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "from sentinelsat.sentinel import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from datetime import date\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the environment variables and settings for downloads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change directory for download\n",
    "os.chdir('D:\\eo_data')\n",
    "\n",
    "## Define search parameters\n",
    "\n",
    "# get geoJSON file with region extent\n",
    "pathJSONFile=\"//dapadfs/workspace_cluster_6/TRANSVERSAL_PROJECTS/MADR/COMPONENTE_2/Imagenes_Satelitales/Sentinel_2/JSON_Ibague/IbagueJSON.geojson\"\n",
    "\n",
    "# set search dates\n",
    "start_date = '20170401'\n",
    "end_date = '20170405'\n",
    "\n",
    "## Specify ESA scihub credentials\n",
    "\n",
    "# store in variables\n",
    "scihub_user = 'asalazarr'\n",
    "scihub_pass = 'tila8sude'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the call to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the API\n",
    "api = SentinelAPI(scihub_user, scihub_pass, 'https://scihub.copernicus.eu/dhus')\n",
    "\n",
    "# download single scene by known product id\n",
    "# api.download(<product_id>)\n",
    "\n",
    "# search by polygon, time, and Hub query keywords\n",
    "footprint = geojson_to_wkt(read_geojson(pathJSONFile))\n",
    "products = api.query(footprint,\n",
    "                     date = (start_date, end_date),\n",
    "                     platformname = 'Sentinel-1')\n",
    "\n",
    "# download all results from the search\n",
    "api.download_all(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\eo_data\\Ibague\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the metadata of the downloaded files\n",
    "#own_files = api.download_all(products)[0]\n",
    "\n",
    "# change the working directory to the location of files\n",
    "os.chdir('D:\\eo_data\\Ibague')\n",
    "print(os.getcwd())\n",
    "# store the files list to a variable\n",
    "eo_files = os.listdir(os.getcwd())\n",
    "#print(eo_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(eo_files)#[0][:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1B_IW_GRDH_1SDV_20170602T104209_20170602T104234_005870_00A4B1_774C was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170614T104210_20170614T104235_006045_00A9D7_4B41 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170626T104210_20170626T104235_006220_00AEED_0591 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170708T104211_20170708T104236_006395_00B3E1_4D33 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170720T104212_20170720T104237_006570_00B8E0_29C0 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170801T104212_20170801T104237_006745_00BDE6_F318 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170813T104213_20170813T104238_006920_00C2FF_99FD was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170825T104213_20170825T104238_007095_00C80F_6556 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170906T104214_20170906T104239_007270_00CD25_4F8F was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170918T104214_20170918T104239_007445_00D249_A0FC was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170930T104215_20170930T104240_007620_00D74F_27DD was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20171012T104215_20171012T104240_007795_00DC4C_C014 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20171024T104215_20171024T104240_007970_00E14C_9097 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20171105T104215_20171105T104240_008145_00E654_FADB was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20171117T104215_20171117T104240_008320_00EB98_BFA2 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20171129T104214_20171129T104239_008495_00F103_C116 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20171211T104214_20171211T104239_008670_00F691_F37A was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20171223T104214_20171223T104239_008845_00FC24_E700 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20180104T104213_20180104T104238_009020_0101D3_78E7 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20180116T104213_20180116T104238_009195_010785_5AA7 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20180128T104212_20180128T104237_009370_010D3E_6BBB was already uncompressed\n"
     ]
    }
   ],
   "source": [
    "# Unzip files\n",
    "import zipfile\n",
    "\n",
    "# Check if a data folder exist\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "    print 'data folder' + ' was created'\n",
    "# Check if the name of the data folder is in\n",
    "if 'data' in eo_files:\n",
    "    eo_files.remove('data')\n",
    "\n",
    "##Todo catch error when a directory is in eo_files\n",
    "for im_id in eo_files:    \n",
    "    if not os.path.exists('data/'+im_id[:-3]+'SAFE'):\n",
    "        print('Unzipping ' + im_id)\n",
    "        zip_ref = zipfile.ZipFile(im_id, 'r')\n",
    "        zip_ref.extractall('data')\n",
    "        zip_ref.close()\n",
    "    else:\n",
    "        print(im_id[:-4] + ' was already uncompressed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing using SNAP\n",
    "The pre-processing workflow (to-be revised) is performed using SNAP Python API, snappy, and currently incudes the following steps:\n",
    "1. Apply orbit\n",
    "2. Speckle filtering\n",
    "3. Terrain correction\n",
    "4. Subset the area of interest\n",
    "5. Logaritmic transformation (to dB)\n",
    "6. Texture analysis\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snappy\n",
    "\n",
    "from snappy import ProductIO\n",
    "from snappy import HashMap\n",
    "import shutil\n",
    "import os  \n",
    "import ast\n",
    "\n",
    "from snappy import GPF\n",
    "\n",
    "GPF.getDefaultInstance().getOperatorSpiRegistry().loadOperatorSpis()\n",
    "HashMap = snappy.jpy.get_type('java.util.HashMap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1B_IW_GRDH_1SDV_20170602T104209_20170602T104234_005870_00A4B1_774C.zip', 'S1B_IW_GRDH_1SDV_20170614T104210_20170614T104235_006045_00A9D7_4B41.zip', 'S1B_IW_GRDH_1SDV_20170626T104210_20170626T104235_006220_00AEED_0591.zip', 'S1B_IW_GRDH_1SDV_20170708T104211_20170708T104236_006395_00B3E1_4D33.zip', 'S1B_IW_GRDH_1SDV_20170720T104212_20170720T104237_006570_00B8E0_29C0.zip', 'S1B_IW_GRDH_1SDV_20170801T104212_20170801T104237_006745_00BDE6_F318.zip', 'S1B_IW_GRDH_1SDV_20170813T104213_20170813T104238_006920_00C2FF_99FD.zip', 'S1B_IW_GRDH_1SDV_20170825T104213_20170825T104238_007095_00C80F_6556.zip', 'S1B_IW_GRDH_1SDV_20170906T104214_20170906T104239_007270_00CD25_4F8F.zip', 'S1B_IW_GRDH_1SDV_20170918T104214_20170918T104239_007445_00D249_A0FC.zip', 'S1B_IW_GRDH_1SDV_20170930T104215_20170930T104240_007620_00D74F_27DD.zip', 'S1B_IW_GRDH_1SDV_20171012T104215_20171012T104240_007795_00DC4C_C014.zip', 'S1B_IW_GRDH_1SDV_20171024T104215_20171024T104240_007970_00E14C_9097.zip', 'S1B_IW_GRDH_1SDV_20171105T104215_20171105T104240_008145_00E654_FADB.zip', 'S1B_IW_GRDH_1SDV_20171117T104215_20171117T104240_008320_00EB98_BFA2.zip', 'S1B_IW_GRDH_1SDV_20171129T104214_20171129T104239_008495_00F103_C116.zip', 'S1B_IW_GRDH_1SDV_20171211T104214_20171211T104239_008670_00F691_F37A.zip', 'S1B_IW_GRDH_1SDV_20171223T104214_20171223T104239_008845_00FC24_E700.zip', 'S1B_IW_GRDH_1SDV_20180104T104213_20180104T104238_009020_0101D3_78E7.zip', 'S1B_IW_GRDH_1SDV_20180116T104213_20180116T104238_009195_010785_5AA7.zip', 'S1B_IW_GRDH_1SDV_20180128T104212_20180128T104237_009370_010D3E_6BBB.zip']\n"
     ]
    }
   ],
   "source": [
    "print(eo_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to get help of the SNAP operators\n",
    "\n",
    "def Op_help(op):\n",
    "        op_spi = snappy.GPF.getDefaultInstance().getOperatorSpiRegistry().getOperatorSpi(op)\n",
    "        print('Op name: {}'.format(op_spi.getOperatorDescriptor().getName()))\n",
    "        print('Op alias: {}\\n'.format(op_spi.getOperatorDescriptor().getAlias()))\n",
    "        print('PARAMETERS:\\n')\n",
    "        param_Desc = op_spi.getOperatorDescriptor().getParameterDescriptors()\n",
    "        for param in param_Desc:\n",
    "            value_set = param_Desc[0].getValueSet()\n",
    "            if len(value_set) == 0:\n",
    "                print('{}: {}\\nDefault Value: {}\\n'.format(param.getName(),param.getDescription(),param.getDefaultValue()))\n",
    "            else:\n",
    "                print('{}: {}\\nDefault Value: {}\\nPossible param: {}\\n'.format(param.getName(),param.getDescription(),param.getDefaultValue(),list(value_set)))\n",
    "\n",
    "#Op_help(\"Multi-Temporal-Speckle-Filter\")\n",
    "#Op_help(\"Collocate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get a list of all Sentinel-1 toolbox operators\n",
    "op_spi = snappy.GPF.getDefaultInstance().getOperatorSpiRegistry().getOperatorSpis().toString()\n",
    "op_list = op_spi.split(', ')\n",
    "listname = []\n",
    "for op_str in op_list:\n",
    "    to_add = op_str\n",
    "    if op_str[0] == '[': to_add = op_str[1:]\n",
    "    elif op_str[-1] == ']': to_add = op_str[:-1]\n",
    "    #if to_add.split('.')[2] == 's1tbx':\n",
    "    listname.append(to_add.split('$')[0])\n",
    "listname.sort()\n",
    "#for name in listname:\n",
    "#    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a variable for the location of the data\n",
    "eo_direc = 'D:/eo_data/Ibague/data/'\n",
    "\n",
    "## Create a dictionary to read Sentinel-1 L1 GRD products\n",
    "product = {}\n",
    "for element in eo_files:\n",
    "    product[element[:-4]] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S1B_IW_GRDH_1SDV_20170918T104214_20170918T104239_007445_00D249_A0FC',\n",
       " 'S1B_IW_GRDH_1SDV_20170720T104212_20170720T104237_006570_00B8E0_29C0',\n",
       " 'S1B_IW_GRDH_1SDV_20171012T104215_20171012T104240_007795_00DC4C_C014',\n",
       " 'S1B_IW_GRDH_1SDV_20170906T104214_20170906T104239_007270_00CD25_4F8F',\n",
       " 'S1B_IW_GRDH_1SDV_20171129T104214_20171129T104239_008495_00F103_C116',\n",
       " 'S1B_IW_GRDH_1SDV_20170626T104210_20170626T104235_006220_00AEED_0591',\n",
       " 'S1B_IW_GRDH_1SDV_20180128T104212_20180128T104237_009370_010D3E_6BBB',\n",
       " 'S1B_IW_GRDH_1SDV_20171223T104214_20171223T104239_008845_00FC24_E700',\n",
       " 'S1B_IW_GRDH_1SDV_20171105T104215_20171105T104240_008145_00E654_FADB',\n",
       " 'S1B_IW_GRDH_1SDV_20170708T104211_20170708T104236_006395_00B3E1_4D33',\n",
       " 'S1B_IW_GRDH_1SDV_20170930T104215_20170930T104240_007620_00D74F_27DD',\n",
       " 'S1B_IW_GRDH_1SDV_20170614T104210_20170614T104235_006045_00A9D7_4B41',\n",
       " 'S1B_IW_GRDH_1SDV_20171024T104215_20171024T104240_007970_00E14C_9097',\n",
       " 'S1B_IW_GRDH_1SDV_20171211T104214_20171211T104239_008670_00F691_F37A',\n",
       " 'S1B_IW_GRDH_1SDV_20170801T104212_20170801T104237_006745_00BDE6_F318',\n",
       " 'S1B_IW_GRDH_1SDV_20180116T104213_20180116T104238_009195_010785_5AA7',\n",
       " 'S1B_IW_GRDH_1SDV_20170825T104213_20170825T104238_007095_00C80F_6556',\n",
       " 'S1B_IW_GRDH_1SDV_20180104T104213_20180104T104238_009020_0101D3_78E7',\n",
       " 'S1B_IW_GRDH_1SDV_20170602T104209_20170602T104234_005870_00A4B1_774C',\n",
       " 'S1B_IW_GRDH_1SDV_20170813T104213_20170813T104238_006920_00C2FF_99FD',\n",
       " 'S1B_IW_GRDH_1SDV_20171117T104215_20171117T104240_008320_00EB98_BFA2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(product.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rint(type(product))\n",
    "\n",
    "# Define the area of interest\n",
    "WKTReader = snappy.jpy.get_type('com.vividsolutions.jts.io.WKTReader')\n",
    "regPath = \"//dapadfs/workspace_cluster_6/TRANSVERSAL_PROJECTS/MADR/COMPONENTE_2/Imagenes_Satelitales/Sentinel_2/\" + \\\n",
    "                      \"JSON_Ibague/IbagueJSON.geojson\"\n",
    "geom = geojson_to_wkt(read_geojson(regPath))\n",
    "\n",
    "# Define polarizations of interest\n",
    "polarizations = ['VV', 'VH']\n",
    "\n",
    "# create the orbit product\n",
    "#product = GPF.createProduct(\"Apply-Orbit-File\", apply_orbit, product)\n",
    "#product.dispose()\n",
    "\n",
    "for key, value in product.iteritems():    \n",
    "    # Read the product\n",
    "    value['GRD'] = ProductIO.readProduct(eo_direc+key+'.SAFE/manifest.safe')\n",
    "    \n",
    "    # Apply orbit\n",
    "    param_orbit = HashMap()\n",
    "    value['orbit'] = GPF.createProduct(\"Apply-Orbit-File\", param_orbit, value['GRD'])\n",
    "    \n",
    "    # The following operations are specific por each polarization    \n",
    "    for pol in polarizations:\n",
    "        # Radiometric calibration\n",
    "        param_calibration = HashMap()\n",
    "        param_calibration.put('outputSigmaBand', True)\n",
    "        param_calibration.put('sourceBands', 'Intensity_' + pol)\n",
    "        param_calibration.put('selectedPolarisations', pol)\n",
    "        param_calibration.put('outputImageScaleInDb', False)\n",
    "        value['calibration_'+pol] = GPF.createProduct(\"Calibration\", param_calibration, value['orbit'])\n",
    "        \n",
    "        # Terrain correction\n",
    "        param_terraincor = HashMap()\n",
    "        param_terraincor.put('demResamplingMethod', 'NEAREST_NEIGHBOUR')\n",
    "        param_terraincor.put('imgResamplingMethod', 'NEAREST_NEIGHBOUR')\n",
    "        param_terraincor.put('applyRadiometricNormalization', True)\n",
    "        param_terraincor.put('demName', 'SRTM 3Sec')\n",
    "        param_terraincor.put('pixelSpacingInMeter', 10.0)\n",
    "        param_terraincor.put('sourceBands', 'Sigma0_' + pol)\n",
    "        param_terraincor.put('mapProjection', 'WGS84(DD)')\n",
    "        value['terraincor_'+pol] = GPF.createProduct(\"Terrain-Correction\", param_terraincor, value['calibration_'+pol])\n",
    "        \n",
    "        # Subset to area of interest\n",
    "        param_subset = HashMap()\n",
    "        param_subset.put('geoRegion', geom)\n",
    "        param_subset.put('outputImageScaleInDb', False)\n",
    "        param_subset.put('sourceBandNames', 'Sigma0_' + pol)\n",
    "        value['subset_'+pol] = GPF.createProduct(\"Subset\", param_subset, value['terraincor_'+pol])\n",
    "        \n",
    "        # define the name of the output\n",
    "        output_name = eo_direc + 'prep/' + key + \"_\" + pol + \"_\"\n",
    "        \n",
    "        # Write the results to files\n",
    "        ProductIO.writeProduct(value['subset_'+pol], output_name, 'BEAM-DIMAP')\n",
    "        \n",
    "        # dispose all the intermediate products\n",
    "        value['calibration_'+pol].dispose()\n",
    "        value['terraincor_'+pol].dispose()\n",
    "        value['subset_'+pol].dispose()\n",
    "        \n",
    "    #dispose all the intermediate products\n",
    "    value['GRD'].dispose()\n",
    "    value['orbit'].dispose()\n",
    "\n",
    "# write the results\n",
    "# ProductIO.writeProduct(orbit_pro, orbit_output, 'BEAM-DIMAP')\n",
    "# print orbit_output + ' was written'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speckle filtering \n",
    "\n",
    "* Multi-temporal speckle filtering\n",
    "* Scale transformation to dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the speckle filtering parameters\n",
    "# specklefilter = HashMap()\n",
    "# specklefilter.put('outputSigmaBand', True)\n",
    "# specklefilter.put('sourceBandNames', 'Sigma0_' + 'VV')\n",
    "# specklefilter.put('filter', 'Gamma Map')\n",
    "# product = GPF.createProduct(\"Speckle-Filter\", specklefilter, product)\n",
    "#calib_pro.dispose()\n",
    "#name = calib_pro.getName()[:32]\n",
    "#speckle_output = speckle_path + name + \"_spk_\" + polarization\n",
    "#ProductIO.writeProduct(speckle_pro, speckle_output, 'BEAM-DIMAP')\n",
    "#filters.append(speckle_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Multi-Temporal-Speckle-Filter Op Parameters:\n",
    "    filter: None --- Default Value: Lee Sigma\n",
    "    nfilterSizeX: The kernel x dimension --- Default Value: 3\n",
    "    nfilterSizeY: The kernel y dimension --- Default Value: 3\n",
    "    ndampingFactor: The damping factor (Frost filter only) --- Default Value: 2\n",
    "    nestimateENL: None --- Default Value: false\n",
    "    nenl: The number of looks --- Default Value: 1.0\n",
    "    nnumLooksStr: None --- nDefault Value: 1\n",
    "    nwindowSize: None --- Default Value: 7x7\n",
    "    ntargetWindowSizeStr: None --- Default Value: 3x3\n",
    "    nsigmaStr: None --- Default Value: 0.9\n",
    "    nanSize: The Adaptive Neighbourhood size --- Default Value: 50\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that iterates over the list of products and stacks the its bands using the SNAP Collocate Operation\n",
    "\n",
    "def stacking_ (prod_list):\n",
    "    if len(prod_list) == 1:\n",
    "        return prod_list[-1]\n",
    "    else:\n",
    "        param_coll = HashMap()\n",
    "        input_coll = HashMap()\n",
    "        input_coll.put(\"master\", prod_list[0])\n",
    "        input_coll.put(\"slave\", prod_list[1])\n",
    "        param_coll.put(\"masterComponentPattern\",\"${ORIGINAL_NAME}_\"+prod_list[0].getName()[17:31])\n",
    "        param_coll.put(\"slaveComponentPattern\",\"${ORIGINAL_NAME}_\"+prod_list[1].getName()[17:31])\n",
    "        prod_list[1] = GPF.createProduct('Collocate', param_coll, input_coll)\n",
    "        return stacking_(prod_list[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to apply multi-temporal speckle filter of a stacked product Sigma0 bands\n",
    "\n",
    "import re\n",
    "\n",
    "def getBandNames (product, sfilter = ''):\n",
    "    \"\"\"\n",
    "    Produces a string to use in the sourceBandNames parameter specification of SNAP operators.\n",
    "    Args:\n",
    "        product (): \n",
    "        sfilter (string): regular expression to filter the name of the bands\n",
    "    Output:\n",
    "        returns a string with comma-separated band names\n",
    "    \"\"\"\n",
    "    band_names = product.getBandNames()\n",
    "    if sfilter != '':\n",
    "        band_names = filter(re.compile(r''+sfilter).search, band_names)\n",
    "    band_names = ','.join(band_names)\n",
    "    return band_names\n",
    "\n",
    "def mtspeckle_sigma0 (stacked_prod):\n",
    "    \"\"\"\n",
    "    Applies the a multi-temporal speckle filter to the a corregistered calibrated product stack. Takes the product bands\n",
    "    which name starts with 'Sigma0'.\n",
    "    \n",
    "    Args:\n",
    "        stacked_prod:\n",
    "    Output:\n",
    "    \"\"\"\n",
    "    param_specklefilter = HashMap()\n",
    "    param_specklefilter.put('sourceBandNames', getBandNames(stacked_prod, sfilter='Sigma0'))\n",
    "    param_specklefilter.put('filter', 'Lee Sigma')\n",
    "    sf_product = GPF.createProduct(\"Multi-Temporal-Speckle-Filter\", param_specklefilter, stacked_prod)\n",
    "    return sf_product\n",
    "\n",
    "def Sigma0_todB (product):\n",
    "    \"\"\"\n",
    "    Transforms the product bands to a logaritmic scale in dB (10*log10[band]).\n",
    "    \n",
    "    Args:\n",
    "        product: product with Sigma0 bands in linear units\n",
    "    Output:\n",
    "    \"\"\"\n",
    "    param_logdB = HashMap()\n",
    "    param_logdB.put('sourceBandNames', getBandNames(product))\n",
    "    db_product = GPF.createProduct(\"LinearToFromdB\", param_logdB, sf_product)\n",
    "    return db_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read all the VV/VH files and store in a list (for further pre-processing)\n",
    "import os, re\n",
    "\n",
    "filenames_VV = filter(re.compile(r'VV_\\.dim').search, os.listdir(os.getcwd()+'\\data\\prep'))\n",
    "filenames_VH = filter(re.compile(r'VH_\\.dim').search, os.listdir(os.getcwd()+'\\data\\prep'))\n",
    "\n",
    "VV_l = []\n",
    "for eofile in pre_VV:\n",
    "    VV_l.append(ProductIO.readProduct(os.getcwd()+'/data/prep/' + eofile))\n",
    "\n",
    "VH_l = []\n",
    "for eofile in pre_VH:\n",
    "    VH_l.append(ProductIO.readProduct(os.getcwd()+'/data/prep/' + eofile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write the results\n",
    "ProductIO.writeProduct(VV_stack, eo_direc + 'prep/VV_stack_', 'BEAM-DIMAP')\n",
    "ProductIO.writeProduct(VH_stack, eo_direc + 'prep/VH_stack_', 'BEAM-DIMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the stacking_ function to get all bands in a same product\n",
    "VV_stack = stacking_(VV_l)\n",
    "VH_stack = stacking_(VH_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_product_VV = mtspeckle_sigma0(VV_stack)\n",
    "sf_product_VH = mtspeckle_sigma0(VH_stack)\n",
    "\n",
    "#ProductIO.writeProduct(sf_product_VV, eo_direc + 'prep/VV_specklefil_', 'BEAM-DIMAP')\n",
    "ProductIO.writeProduct(sf_product_VH, eo_direc + 'prep/VH_specklefil_', 'BEAM-DIMAP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_logdB = HashMap()\n",
    "param_logdB.put('sourceBandNames', getBandNames(sf_product_VH))\n",
    "db_product = GPF.createProduct(\"LinearToFromdB\", param_logdB, sf_product_VH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductIO.writeProduct(db_product, eo_direc + 'prep/VH_specklefil_dB', 'BEAM-DIMAP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texture analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# paramaters for GLCM texture analysis\n",
    "paramGLCM = HashMap()\n",
    "paramGLCM.put('sourceBandNames', 'Sigma0_' + 'VV')\n",
    "paramGLCM.put('windowSizeStr', '5x5')\n",
    "paramGLCM.put('quantizerStr', 'Probabilistic Quantizer')\n",
    "paramGLCM.put('quantizationLevelsStr', '16')\n",
    "paramGLCM.put('displacement','4' )\n",
    "paramGLCM.put('outputContrast','true')\n",
    "paramGLCM.put('outputDissimilarity','true')\n",
    "paramGLCM.put('outputHomogeneity','true')\n",
    "paramGLCM.put('outputASM','true')\n",
    "paramGLCM.put('outputEnergy','true')\n",
    "paramGLCM.put('outputMean','true')\n",
    "paramGLCM.put('outputVariance','true')\n",
    "paramGLCM.put('outputCorrelation','true')\n",
    "\n",
    "product = GPF.createProduct(\"GLCM\", paramGLCM, product)\n",
    "\n",
    "#GLCM_output = \"C:/Users/asalazar/Documents/Ibague/_subset_VV\"\n",
    "\n",
    "#ProductIO.writeProduct(targetGCLM, GLCM_output, 'BEAM-DIMAP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor function. Could be useful for monitoring progress of file writing. To test!\n",
    "\n",
    "from snappy import jpy\n",
    "\n",
    "def createProgressMonitor():\n",
    "    PWPM = jpy.get_type('com.bc.ceres.core.PrintWriterProgressMonitor')\n",
    "    JavaSystem = jpy.get_type('java.lang.System')\n",
    "    monitor = PWPM(JavaSystem.out)\n",
    "    return monitor\n",
    "\n",
    "ProductIO.writeProduct(product, 'C:/Users/asalazar/Documents/Ibague/GLCM_output', 'BEAM-DIMAP', pm = createProgressMonitor())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
