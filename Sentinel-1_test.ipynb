{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentinel-1 data download using sentinelsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "from sentinelsat.sentinel import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from datetime import date\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the environment variables and settings for downloads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change directory for download\n",
    "os.chdir('D:\\eo_data')\n",
    "\n",
    "## Define search parameters\n",
    "\n",
    "# get geoJSON file with region extent\n",
    "pathJSONFile=\"//dapadfs/workspace_cluster_6/TRANSVERSAL_PROJECTS/MADR/COMPONENTE_2/Imagenes_Satelitales/Sentinel_2/JSON_Ibague/IbagueJSON.geojson\"\n",
    "\n",
    "# set search dates\n",
    "start_date = '20170401'\n",
    "end_date = '20170405'\n",
    "\n",
    "## Specify ESA scihub credentials\n",
    "\n",
    "# store in variables\n",
    "scihub_user = 'asalazarr'\n",
    "scihub_pass = 'tila8sude'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the call to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SentinelAPIError",
     "evalue": "HTTP status 503 Service Unavailable: \nThe Copernicus Open Access Hub\n\n# The Copernicus Open Access Hub will be back soon!\n\nSorry for the inconvenience,  \nwe're performing some maintenance at the moment.  \n\n<https://scihub.copernicus.eu/news/News00296>\n\nWe'll be back online shortly!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSentinelAPIError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-710f834819eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m products = api.query(footprint,\n\u001b[0;32m     10\u001b[0m                      \u001b[0mdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                      platformname = 'Sentinel-1')\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# download all results from the search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sentinelsat\\sentinel.pyc\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, area, date, raw, area_relation, order_by, limit, offset, **keywords)\u001b[0m\n\u001b[0;32m    142\u001b[0m                          \"({:.1%} of the limit)\".format(factor))\n\u001b[0;32m    143\u001b[0m             \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__cause__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Found %s products\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_parse_opensearch_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSentinelAPIError\u001b[0m: HTTP status 503 Service Unavailable: \nThe Copernicus Open Access Hub\n\n# The Copernicus Open Access Hub will be back soon!\n\nSorry for the inconvenience,  \nwe're performing some maintenance at the moment.  \n\n<https://scihub.copernicus.eu/news/News00296>\n\nWe'll be back online shortly!"
     ]
    }
   ],
   "source": [
    "# connect to the API\n",
    "api = SentinelAPI(scihub_user, scihub_pass, 'https://scihub.copernicus.eu/dhus')\n",
    "\n",
    "# download single scene by known product id\n",
    "# api.download(<product_id>)\n",
    "\n",
    "# search by polygon, time, and Hub query keywords\n",
    "footprint = geojson_to_wkt(read_geojson(pathJSONFile))\n",
    "products = api.query(footprint,\n",
    "                     date = (start_date, end_date),\n",
    "                     platformname = 'Sentinel-1')\n",
    "\n",
    "# download all results from the search\n",
    "api.download_all(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\eo_data\\Ibague\n",
      "['S1B_IW_GRDH_1SDV_20170602T104209_20170602T104234_005870_00A4B1_774C.zip', 'S1B_IW_GRDH_1SDV_20170614T104210_20170614T104235_006045_00A9D7_4B41.zip', 'S1B_IW_GRDH_1SDV_20170626T104210_20170626T104235_006220_00AEED_0591.zip', 'S1B_IW_GRDH_1SDV_20170708T104211_20170708T104236_006395_00B3E1_4D33.zip', 'S1B_IW_GRDH_1SDV_20170720T104212_20170720T104237_006570_00B8E0_29C0.zip', 'S1B_IW_GRDH_1SDV_20170801T104212_20170801T104237_006745_00BDE6_F318.zip', 'S1B_IW_GRDH_1SDV_20170813T104213_20170813T104238_006920_00C2FF_99FD.zip', 'S1B_IW_GRDH_1SDV_20170825T104213_20170825T104238_007095_00C80F_6556.zip', 'S1B_IW_GRDH_1SDV_20170906T104214_20170906T104239_007270_00CD25_4F8F.zip', 'S1B_IW_GRDH_1SDV_20170918T104214_20170918T104239_007445_00D249_A0FC.zip', 'S1B_IW_GRDH_1SDV_20170930T104215_20170930T104240_007620_00D74F_27DD.zip', 'S1B_IW_GRDH_1SDV_20171012T104215_20171012T104240_007795_00DC4C_C014.zip', 'S1B_IW_GRDH_1SDV_20171024T104215_20171024T104240_007970_00E14C_9097.zip', 'S1B_IW_GRDH_1SDV_20171105T104215_20171105T104240_008145_00E654_FADB.zip', 'S1B_IW_GRDH_1SDV_20171117T104215_20171117T104240_008320_00EB98_BFA2.zip', 'S1B_IW_GRDH_1SDV_20171129T104214_20171129T104239_008495_00F103_C116.zip', 'S1B_IW_GRDH_1SDV_20171211T104214_20171211T104239_008670_00F691_F37A.zip', 'S1B_IW_GRDH_1SDV_20171223T104214_20171223T104239_008845_00FC24_E700.zip', 'S1B_IW_GRDH_1SDV_20180104T104213_20180104T104238_009020_0101D3_78E7.zip', 'S1B_IW_GRDH_1SDV_20180116T104213_20180116T104238_009195_010785_5AA7.zip', 'S1B_IW_GRDH_1SDV_20180128T104212_20180128T104237_009370_010D3E_6BBB.zip']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the metadata of the downloaded files\n",
    "#own_files = api.download_all(products)[0]\n",
    "\n",
    "# change the working directory to the location of files\n",
    "os.chdir('D:\\eo_data\\Ibague')\n",
    "print(os.getcwd())\n",
    "# store the files list to a variable\n",
    "eo_files = os.listdir(os.getcwd())\n",
    "#print(eo_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S1B_IW_GRDH_1SDV_20170602T104209_20170602T104234_005870_00A4B1_774C.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eo_files[0][:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1B_IW_GRDH_1SDV_20170602T104209_20170602T104234_005870_00A4B1_774C was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170614T104210_20170614T104235_006045_00A9D7_4B41 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170626T104210_20170626T104235_006220_00AEED_0591 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170708T104211_20170708T104236_006395_00B3E1_4D33 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170720T104212_20170720T104237_006570_00B8E0_29C0 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170801T104212_20170801T104237_006745_00BDE6_F318 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170813T104213_20170813T104238_006920_00C2FF_99FD was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170825T104213_20170825T104238_007095_00C80F_6556 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170906T104214_20170906T104239_007270_00CD25_4F8F was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170918T104214_20170918T104239_007445_00D249_A0FC was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170930T104215_20170930T104240_007620_00D74F_27DD was already uncompressed\n",
      "Unzipping S1B_IW_GRDH_1SDV_20171012T104215_20171012T104240_007795_00DC4C_C014.zip\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-1e0b079f50db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unzipping '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mim_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mzip_ref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mzip_ref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mzip_ref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\zipfile.pyc\u001b[0m in \u001b[0;36mextractall\u001b[1;34m(self, path, members, pwd)\u001b[0m\n\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_extract_member\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmember\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\zipfile.pyc\u001b[0m in \u001b[0;36mextract\u001b[1;34m(self, member, path, pwd)\u001b[0m\n\u001b[0;32m   1026\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1028\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmembers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\zipfile.pyc\u001b[0m in \u001b[0;36m_extract_member\u001b[1;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m              \u001b[0mfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m             \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1085\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\shutil.pyc\u001b[0m in \u001b[0;36mcopyfileobj\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mfdst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_samefile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Unzip files\n",
    "import zipfile\n",
    "\n",
    "for im_id in eo_files:\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "        print 'data folder' + ' was created'\n",
    "    if not os.path.exists('data/'+im_id[:-3]+'SAFE'):\n",
    "        print('Unzipping ' + im_id)\n",
    "        zip_ref = zipfile.ZipFile(im_id, 'r')\n",
    "        zip_ref.extractall('data')\n",
    "        zip_ref.close()\n",
    "    else:\n",
    "        print(im_id[:-4] + ' was already uncompressed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing using SNAP\n",
    "The pre-processing workflow (to-be revised) is performed using SNAP Python API, snappy, and currently incudes the following steps:\n",
    "1. Apply orbit\n",
    "2. Speckle filtering\n",
    "3. Terrain correction\n",
    "4. Subset the area of interest\n",
    "5. Logaritmic transformation (to dB)\n",
    "6. Texture analysis\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'515c867e-24ad-4b62-87ea-fab40eac376b',\n",
       " u'4f324c66-865a-46a8-a35e-ccb3da946980',\n",
       " u'd6d804e3-b03f-434b-8ca6-fd2f66ba6e43']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snappy\n",
    "\n",
    "from snappy import ProductIO\n",
    "from snappy import HashMap\n",
    "import shutil\n",
    "import os  \n",
    "import ast\n",
    "\n",
    "from snappy import GPF\n",
    "\n",
    "GPF.getDefaultInstance().getOperatorSpiRegistry().loadOperatorSpis()\n",
    "HashMap = snappy.jpy.get_type('java.util.HashMap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## read Sentinel-1 L1 SLC product\n",
    "product = ProductIO.readProduct(\"C:/Users/asalazar/Documents/Ibague/S1B_IW_GRDH_1SSV_20170403T104206_20170403T104231_004995_008BC6_228A.SAFE/manifest.safe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'org.esa.snap.core.datamodel.Product'>\n"
     ]
    }
   ],
   "source": [
    "print(type(product))\n",
    "\n",
    "# create a HashMap for GPF parameters\n",
    "apply_orbit = HashMap()\n",
    "# define the name of the output\n",
    "name = product.getName()[:32]\n",
    "orbit_output = \"C:/Users/asalazar/Documents/Ibague/\" + name + \"_orbit_\"\n",
    "\n",
    "# create the orbit product\n",
    "product = GPF.createProduct(\"Apply-Orbit-File\", apply_orbit, product)\n",
    "#product.dispose()\n",
    "\n",
    "# write the results\n",
    "# ProductIO.writeProduct(orbit_pro, orbit_output, 'BEAM-DIMAP')\n",
    "# print orbit_output + ' was written'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next pre-processing steps need to be done for each polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amplitude_VV', 'Intensity_VV']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pols = ['VV', 'VH']\n",
    "list(product.getBandNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the calibration parameters\n",
    "calibration = HashMap()\n",
    "calibration.put('outputSigmaBand', True)\n",
    "calibration.put('sourceBands', 'Intensity_' + 'VV')\n",
    "calibration.put('selectedPolarisations', 'VV')\n",
    "calibration.put('outputImageScaleInDb', False)\n",
    "\n",
    "name = product.getName()[:32]\n",
    "#calib = \"C:/Users/asalazar/Documents/Ibague/\" + name + \"_calibrate_\" + 'VV'\n",
    "\n",
    "product = GPF.createProduct(\"Calibration\", calibration, product)\n",
    "#orbit_pro.dispose()\n",
    "\n",
    "#ProductIO.writeProduct(calib_pro, calib, 'BEAM-DIMAP')\n",
    "#print 'the calibration product was writed'\n",
    "#calibrates.append(calib_pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speckle filtering \n",
    "\n",
    "How is it different time-series speckle filtering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the speckle filtering parameters\n",
    "specklefilter = HashMap()\n",
    "specklefilter.put('outputSigmaBand', True)\n",
    "specklefilter.put('sourceBandNames', 'Sigma0_' + 'VV')\n",
    "specklefilter.put('filter', 'Gamma Map')\n",
    "\n",
    "product = GPF.createProduct(\"Speckle-Filter\", specklefilter, product)\n",
    "#calib_pro.dispose()\n",
    "\n",
    "#name = calib_pro.getName()[:32]\n",
    "#speckle_output = speckle_path + name + \"_spk_\" + polarization\n",
    "#ProductIO.writeProduct(speckle_pro, speckle_output, 'BEAM-DIMAP')\n",
    "#filters.append(speckle_pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terrain correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define terrain correction parameters\n",
    "terrain_correction = HashMap()\n",
    "terrain_correction.put('demResamplingMethod', 'NEAREST_NEIGHBOUR')\n",
    "terrain_correction.put('imgResamplingMethod', 'NEAREST_NEIGHBOUR')\n",
    "terrain_correction.put('applyRadiometricNormalization', True)\n",
    "terrain_correction.put('demName', 'SRTM 3Sec')\n",
    "terrain_correction.put('pixelSpacingInMeter', 10.0)\n",
    "terrain_correction.put('sourceBands', 'Sigma0_' + 'VV')\n",
    "terrain_correction.put('mapProjection', 'WGS84(DD)')\n",
    "\n",
    "#terrain_correction.put('saveSigmaNought', True)\n",
    "#terrain_correction.put('incidenceAngleForSigma0', 'Use projected local incidence angle from DEM')\n",
    "\n",
    "product = GPF.createProduct(\"Terrain-Correction\", terrain_correction, product)\n",
    "#speckle_pro.dispose()\n",
    "\n",
    "#terrain_output = terrain_path + name + \"_corrected_\" + polarization\n",
    "#ProductIO.writeProduct(terrain_pro, terrain_output, 'BEAM-DIMAP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def SubsetSentProduct(products,polarization,wkt,Subset_path,write_Product):\n",
    "\n",
    "# read the polygon to make the subset\n",
    "WKTReader = snappy.jpy.get_type('com.vividsolutions.jts.io.WKTReader')\n",
    "geom = geojson_to_wkt(read_geojson(pathJSONFile))\n",
    "\n",
    "# subset operation parameters\n",
    "subsettings = HashMap()\n",
    "subsettings.put('geoRegion', geom)\n",
    "subsettings.put('outputImageScaleInDb', False)\n",
    "subsettings.put('sourceBandNames', 'Sigma0_' + 'VV')\n",
    "\n",
    "product = GPF.createProduct(\"Subset\", subsettings, product)\n",
    "#terrain_pro.dispose()\n",
    "\n",
    "\n",
    "#name = product.getName()[:32]\n",
    "#ProductIO.writeProduct(SubsetProduct, Subset_output, 'BEAM-DIMAP')\n",
    "#print 'the Subset product was writed'\n",
    "#subsets.append(SubsetProduct)\n",
    "#return(subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logaritmic transformation (to dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set log-scale transformation parameters\n",
    "paramToDB = HashMap()\n",
    "paramToDB.put('sourceBandNames', 'Sigma0_' + 'VV')\n",
    "\n",
    "# make the log transformation\n",
    "product = GPF.createProduct(\"LinearToFromdB\", paramToDB, product)\n",
    "#SubsetProduct.dispose()\n",
    "\n",
    "# write the results\n",
    "#dB_output = \"C:/Users/asalazar/Documents/Ibague/_dB_\"\n",
    "#ProductIO.writeProduct(targetDB, dB_output, 'BEAM-DIMAP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sigma0_VV_db']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(product.getBandNames())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texture analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# paramaters for GLCM texture analysis\n",
    "paramGLCM = HashMap()\n",
    "paramGLCM.put('sourceBandNames', 'Sigma0_' + 'VV')\n",
    "paramGLCM.put('windowSizeStr', '5x5')\n",
    "paramGLCM.put('quantizerStr', 'Probabilistic Quantizer')\n",
    "paramGLCM.put('quantizationLevelsStr', '16')\n",
    "paramGLCM.put('displacement','4' )\n",
    "paramGLCM.put('outputContrast','true')\n",
    "paramGLCM.put('outputDissimilarity','true')\n",
    "paramGLCM.put('outputHomogeneity','true')\n",
    "paramGLCM.put('outputASM','true')\n",
    "paramGLCM.put('outputEnergy','true')\n",
    "paramGLCM.put('outputMean','true')\n",
    "paramGLCM.put('outputVariance','true')\n",
    "paramGLCM.put('outputCorrelation','true')\n",
    "\n",
    "product = GPF.createProduct(\"GLCM\", paramGLCM, product)\n",
    "\n",
    "#GLCM_output = \"C:/Users/asalazar/Documents/Ibague/_subset_VV\"\n",
    "\n",
    "#ProductIO.writeProduct(targetGCLM, GLCM_output, 'BEAM-DIMAP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sigma0_VV_db_Contrast',\n",
       " 'Sigma0_VV_db_Dissimilarity',\n",
       " 'Sigma0_VV_db_Homogeneity',\n",
       " 'Sigma0_VV_db_ASM',\n",
       " 'Sigma0_VV_db_Energy',\n",
       " 'Sigma0_VV_db_MAX',\n",
       " 'Sigma0_VV_db_Entropy',\n",
       " 'Sigma0_VV_db_GLCMMean',\n",
       " 'Sigma0_VV_db_GLCMVariance',\n",
       " 'Sigma0_VV_db_GLCMCorrelation']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(product.getBandNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snappy import jpy\n",
    "\n",
    "def createProgressMonitor():\n",
    "    PWPM = jpy.get_type('com.bc.ceres.core.PrintWriterProgressMonitor')\n",
    "    JavaSystem = jpy.get_type('java.lang.System')\n",
    "    monitor = PWPM(JavaSystem.out)\n",
    "    return monitor\n",
    "\n",
    "ProductIO.writeProduct(product, 'C:/Users/asalazar/Documents/Ibague/GLCM_output', 'BEAM-DIMAP', pm = createProgressMonitor())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
