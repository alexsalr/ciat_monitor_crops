{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentinel-1 data download using sentinelsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "from sentinelsat.sentinel import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from datetime import date\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the environment variables and settings for downloads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change directory for download\n",
    "os.chdir('D:\\eo_data')\n",
    "\n",
    "## Define search parameters\n",
    "\n",
    "# get geoJSON file with region extent\n",
    "pathJSONFile=\"//dapadfs/workspace_cluster_6/TRANSVERSAL_PROJECTS/MADR/COMPONENTE_2/Imagenes_Satelitales/Sentinel_2/JSON_Ibague/IbagueJSON.geojson\"\n",
    "\n",
    "# set search dates\n",
    "start_date = '20170401'\n",
    "end_date = '20170405'\n",
    "\n",
    "## Specify ESA scihub credentials\n",
    "\n",
    "# store in variables\n",
    "scihub_user = 'asalazarr'\n",
    "scihub_pass = 'tila8sude'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the call to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SentinelAPIError",
     "evalue": "HTTP status 503 Service Unavailable: \nThe Copernicus Open Access Hub\n\n# The Copernicus Open Access Hub will be back soon!\n\nSorry for the inconvenience,  \nwe're performing some maintenance at the moment.  \n\n<https://scihub.copernicus.eu/news/News00296>\n\nWe'll be back online shortly!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSentinelAPIError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-710f834819eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m products = api.query(footprint,\n\u001b[0;32m     10\u001b[0m                      \u001b[0mdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                      platformname = 'Sentinel-1')\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# download all results from the search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sentinelsat\\sentinel.pyc\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, area, date, raw, area_relation, order_by, limit, offset, **keywords)\u001b[0m\n\u001b[0;32m    142\u001b[0m                          \"({:.1%} of the limit)\".format(factor))\n\u001b[0;32m    143\u001b[0m             \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__cause__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Found %s products\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_parse_opensearch_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSentinelAPIError\u001b[0m: HTTP status 503 Service Unavailable: \nThe Copernicus Open Access Hub\n\n# The Copernicus Open Access Hub will be back soon!\n\nSorry for the inconvenience,  \nwe're performing some maintenance at the moment.  \n\n<https://scihub.copernicus.eu/news/News00296>\n\nWe'll be back online shortly!"
     ]
    }
   ],
   "source": [
    "# connect to the API\n",
    "api = SentinelAPI(scihub_user, scihub_pass, 'https://scihub.copernicus.eu/dhus')\n",
    "\n",
    "# download single scene by known product id\n",
    "# api.download(<product_id>)\n",
    "\n",
    "# search by polygon, time, and Hub query keywords\n",
    "footprint = geojson_to_wkt(read_geojson(pathJSONFile))\n",
    "products = api.query(footprint,\n",
    "                     date = (start_date, end_date),\n",
    "                     platformname = 'Sentinel-1')\n",
    "\n",
    "# download all results from the search\n",
    "api.download_all(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the metadata of the downloaded files\n",
    "down_files = api.download_all(products)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping S1B_IW_RAW__0SSV_20170403T104202_20170403T104235_004995_008BC6_71EF\n"
     ]
    }
   ],
   "source": [
    "# Unzip files\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "for im_id in down_files.keys():\n",
    "    file_name = down_files.get(im_id).get('title')\n",
    "    print('Unzipping ' + file_name)\n",
    "    if not os.path.exists('Ibague'):\n",
    "        os.makedirs('Ibague')\n",
    "        print 'Ibague' + ' was created'\n",
    "    zip_ref = zipfile.ZipFile(file_name+'.zip', 'r')\n",
    "    zip_ref.extractall('Ibague')\n",
    "    zip_ref.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing using SNAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'515c867e-24ad-4b62-87ea-fab40eac376b',\n",
       " u'4f324c66-865a-46a8-a35e-ccb3da946980',\n",
       " u'd6d804e3-b03f-434b-8ca6-fd2f66ba6e43']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snappy\n",
    "\n",
    "from snappy import ProductIO\n",
    "from snappy import HashMap\n",
    "import shutil\n",
    "import os  \n",
    "import ast\n",
    "\n",
    "from snappy import GPF\n",
    "\n",
    "GPF.getDefaultInstance().getOperatorSpiRegistry().loadOperatorSpis()\n",
    "HashMap = snappy.jpy.get_type('java.util.HashMap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## read Sentinel-1 L1 SLC product\n",
    "product = ProductIO.readProduct(\"C:/Users/asalazar/Documents/Ibague/S1B_IW_GRDH_1SSV_20170403T104206_20170403T104231_004995_008BC6_228A.SAFE/manifest.safe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'org.esa.snap.core.datamodel.Product'>\n"
     ]
    }
   ],
   "source": [
    "print(type(product))\n",
    "\n",
    "# create a HashMap for GPF parameters\n",
    "apply_orbit = HashMap()\n",
    "# define the name of the output\n",
    "name = product.getName()[:32]\n",
    "orbit_output = \"C:/Users/asalazar/Documents/Ibague/\" + name + \"_orbit_\"\n",
    "\n",
    "# create the orbit product\n",
    "product = GPF.createProduct(\"Apply-Orbit-File\", apply_orbit, product)\n",
    "#product.dispose()\n",
    "\n",
    "# write the results\n",
    "# ProductIO.writeProduct(orbit_pro, orbit_output, 'BEAM-DIMAP')\n",
    "# print orbit_output + ' was written'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next pre-processing steps need to be done for each polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amplitude_VV', 'Intensity_VV']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pols = ['VV', 'VH']\n",
    "list(product.getBandNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the calibration parameters\n",
    "calibration = HashMap()\n",
    "calibration.put('outputSigmaBand', True)\n",
    "calibration.put('sourceBands', 'Intensity_' + 'VV')\n",
    "calibration.put('selectedPolarisations', 'VV')\n",
    "calibration.put('outputImageScaleInDb', False)\n",
    "\n",
    "name = product.getName()[:32]\n",
    "#calib = \"C:/Users/asalazar/Documents/Ibague/\" + name + \"_calibrate_\" + 'VV'\n",
    "\n",
    "product = GPF.createProduct(\"Calibration\", calibration, product)\n",
    "#orbit_pro.dispose()\n",
    "\n",
    "#ProductIO.writeProduct(calib_pro, calib, 'BEAM-DIMAP')\n",
    "#print 'the calibration product was writed'\n",
    "#calibrates.append(calib_pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speckle filtering \n",
    "\n",
    "How is it different time-series speckle filtering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the speckle filtering parameters\n",
    "specklefilter = HashMap()\n",
    "specklefilter.put('outputSigmaBand', True)\n",
    "specklefilter.put('sourceBandNames', 'Sigma0_' + 'VV')\n",
    "specklefilter.put('filter', 'Gamma Map')\n",
    "\n",
    "product = GPF.createProduct(\"Speckle-Filter\", specklefilter, product)\n",
    "#calib_pro.dispose()\n",
    "\n",
    "#name = calib_pro.getName()[:32]\n",
    "#speckle_output = speckle_path + name + \"_spk_\" + polarization\n",
    "#ProductIO.writeProduct(speckle_pro, speckle_output, 'BEAM-DIMAP')\n",
    "#filters.append(speckle_pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terrain correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define terrain correction parameters\n",
    "terrain_correction = HashMap()\n",
    "terrain_correction.put('demResamplingMethod', 'NEAREST_NEIGHBOUR')\n",
    "terrain_correction.put('imgResamplingMethod', 'NEAREST_NEIGHBOUR')\n",
    "terrain_correction.put('applyRadiometricNormalization', True)\n",
    "terrain_correction.put('demName', 'SRTM 3Sec')\n",
    "terrain_correction.put('pixelSpacingInMeter', 10.0)\n",
    "terrain_correction.put('sourceBands', 'Sigma0_' + 'VV')\n",
    "terrain_correction.put('mapProjection', 'WGS84(DD)')\n",
    "\n",
    "#terrain_correction.put('saveSigmaNought', True)\n",
    "#terrain_correction.put('incidenceAngleForSigma0', 'Use projected local incidence angle from DEM')\n",
    "\n",
    "product = GPF.createProduct(\"Terrain-Correction\", terrain_correction, product)\n",
    "#speckle_pro.dispose()\n",
    "\n",
    "#terrain_output = terrain_path + name + \"_corrected_\" + polarization\n",
    "#ProductIO.writeProduct(terrain_pro, terrain_output, 'BEAM-DIMAP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def SubsetSentProduct(products,polarization,wkt,Subset_path,write_Product):\n",
    "\n",
    "# read the polygon to make the subset\n",
    "WKTReader = snappy.jpy.get_type('com.vividsolutions.jts.io.WKTReader')\n",
    "geom = geojson_to_wkt(read_geojson(pathJSONFile))\n",
    "\n",
    "# subset operation parameters\n",
    "subsettings = HashMap()\n",
    "subsettings.put('geoRegion', geom)\n",
    "subsettings.put('outputImageScaleInDb', False)\n",
    "subsettings.put('sourceBandNames', 'Sigma0_' + 'VV')\n",
    "\n",
    "product = GPF.createProduct(\"Subset\", subsettings, product)\n",
    "#terrain_pro.dispose()\n",
    "\n",
    "\n",
    "#name = product.getName()[:32]\n",
    "#ProductIO.writeProduct(SubsetProduct, Subset_output, 'BEAM-DIMAP')\n",
    "#print 'the Subset product was writed'\n",
    "#subsets.append(SubsetProduct)\n",
    "#return(subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logaritmic transformation (to dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set log-scale transformation parameters\n",
    "paramToDB = HashMap()\n",
    "paramToDB.put('sourceBandNames', 'Sigma0_' + 'VV')\n",
    "\n",
    "# make the log transformation\n",
    "product = GPF.createProduct(\"LinearToFromdB\", paramToDB, product)\n",
    "#SubsetProduct.dispose()\n",
    "\n",
    "# write the results\n",
    "#dB_output = \"C:/Users/asalazar/Documents/Ibague/_dB_\"\n",
    "#ProductIO.writeProduct(targetDB, dB_output, 'BEAM-DIMAP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sigma0_VV_db']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(product.getBandNames())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texture analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# paramaters for GLCM texture analysis\n",
    "paramGLCM = HashMap()\n",
    "paramGLCM.put('sourceBandNames', 'Sigma0_' + 'VV')\n",
    "paramGLCM.put('windowSizeStr', '5x5')\n",
    "paramGLCM.put('quantizerStr', 'Probabilistic Quantizer')\n",
    "paramGLCM.put('quantizationLevelsStr', '16')\n",
    "paramGLCM.put('displacement','4' )\n",
    "paramGLCM.put('outputContrast','true')\n",
    "paramGLCM.put('outputDissimilarity','true')\n",
    "paramGLCM.put('outputHomogeneity','true')\n",
    "paramGLCM.put('outputASM','true')\n",
    "paramGLCM.put('outputEnergy','true')\n",
    "paramGLCM.put('outputMean','true')\n",
    "paramGLCM.put('outputVariance','true')\n",
    "paramGLCM.put('outputCorrelation','true')\n",
    "\n",
    "product = GPF.createProduct(\"GLCM\", paramGLCM, product)\n",
    "\n",
    "#GLCM_output = \"C:/Users/asalazar/Documents/Ibague/_subset_VV\"\n",
    "\n",
    "#ProductIO.writeProduct(targetGCLM, GLCM_output, 'BEAM-DIMAP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sigma0_VV_db_Contrast',\n",
       " 'Sigma0_VV_db_Dissimilarity',\n",
       " 'Sigma0_VV_db_Homogeneity',\n",
       " 'Sigma0_VV_db_ASM',\n",
       " 'Sigma0_VV_db_Energy',\n",
       " 'Sigma0_VV_db_MAX',\n",
       " 'Sigma0_VV_db_Entropy',\n",
       " 'Sigma0_VV_db_GLCMMean',\n",
       " 'Sigma0_VV_db_GLCMVariance',\n",
       " 'Sigma0_VV_db_GLCMCorrelation']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(product.getBandNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snappy import jpy\n",
    "\n",
    "def createProgressMonitor():\n",
    "    PWPM = jpy.get_type('com.bc.ceres.core.PrintWriterProgressMonitor')\n",
    "    JavaSystem = jpy.get_type('java.lang.System')\n",
    "    monitor = PWPM(JavaSystem.out)\n",
    "    return monitor\n",
    "\n",
    "ProductIO.writeProduct(product, 'C:/Users/asalazar/Documents/Ibague/GLCM_output', 'BEAM-DIMAP', pm = createProgressMonitor())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
