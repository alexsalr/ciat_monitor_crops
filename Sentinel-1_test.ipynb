{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentinel-1 data download using sentinelsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "from sentinelsat.sentinel import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from datetime import date\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the environment variables and settings for downloads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change directory for download\n",
    "os.chdir('D:\\eo_data')\n",
    "\n",
    "## Define search parameters\n",
    "\n",
    "# get geoJSON file with region extent\n",
    "pathJSONFile=\"//dapadfs/workspace_cluster_6/TRANSVERSAL_PROJECTS/MADR/COMPONENTE_2/Imagenes_Satelitales/Sentinel_2/JSON_Ibague/IbagueJSON.geojson\"\n",
    "\n",
    "# set search dates\n",
    "start_date = '20170401'\n",
    "end_date = '20170405'\n",
    "\n",
    "## Specify ESA scihub credentials\n",
    "\n",
    "# store in variables\n",
    "scihub_user = 'asalazarr'\n",
    "scihub_pass = 'tila8sude'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the call to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the API\n",
    "api = SentinelAPI(scihub_user, scihub_pass, 'https://scihub.copernicus.eu/dhus')\n",
    "\n",
    "# download single scene by known product id\n",
    "# api.download(<product_id>)\n",
    "\n",
    "# search by polygon, time, and Hub query keywords\n",
    "## TO-DO: add type of product to the search terms\n",
    "footprint = geojson_to_wkt(read_geojson(pathJSONFile))\n",
    "products = api.query(footprint,\n",
    "                     date = (start_date, end_date),\n",
    "                     platformname = 'Sentinel-1')\n",
    "\n",
    "# download all results from the search\n",
    "api.download_all(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\eo_data\\Ibague\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the metadata of the downloaded files\n",
    "#own_files = api.download_all(products)[0]\n",
    "\n",
    "# change the working directory to the location of files\n",
    "os.chdir('D:\\eo_data\\Ibague')\n",
    "print(os.getcwd())\n",
    "# store the files list to a variable\n",
    "eo_files = os.listdir(os.getcwd())\n",
    "#print(eo_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(eo_files)#[0][:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1B_IW_GRDH_1SDV_20170602T104209_20170602T104234_005870_00A4B1_774C was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170614T104210_20170614T104235_006045_00A9D7_4B41 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170626T104210_20170626T104235_006220_00AEED_0591 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170708T104211_20170708T104236_006395_00B3E1_4D33 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170720T104212_20170720T104237_006570_00B8E0_29C0 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170801T104212_20170801T104237_006745_00BDE6_F318 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170813T104213_20170813T104238_006920_00C2FF_99FD was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170825T104213_20170825T104238_007095_00C80F_6556 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170906T104214_20170906T104239_007270_00CD25_4F8F was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170918T104214_20170918T104239_007445_00D249_A0FC was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20170930T104215_20170930T104240_007620_00D74F_27DD was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20171012T104215_20171012T104240_007795_00DC4C_C014 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20171024T104215_20171024T104240_007970_00E14C_9097 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20171105T104215_20171105T104240_008145_00E654_FADB was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20171117T104215_20171117T104240_008320_00EB98_BFA2 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20171129T104214_20171129T104239_008495_00F103_C116 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20171211T104214_20171211T104239_008670_00F691_F37A was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20171223T104214_20171223T104239_008845_00FC24_E700 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20180104T104213_20180104T104238_009020_0101D3_78E7 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20180116T104213_20180116T104238_009195_010785_5AA7 was already uncompressed\n",
      "S1B_IW_GRDH_1SDV_20180128T104212_20180128T104237_009370_010D3E_6BBB was already uncompressed\n"
     ]
    }
   ],
   "source": [
    "# Unzip files\n",
    "import zipfile\n",
    "\n",
    "# Check if a data folder exist\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "    print 'data folder' + ' was created'\n",
    "# Check if the name of the data folder is in\n",
    "if 'data' in eo_files:\n",
    "    eo_files.remove('data')\n",
    "\n",
    "##Todo catch error when a directory is in eo_files\n",
    "for im_id in eo_files:    \n",
    "    if not os.path.exists('data/'+im_id[:-3]+'SAFE'):\n",
    "        print('Unzipping ' + im_id)\n",
    "        zip_ref = zipfile.ZipFile(im_id, 'r')\n",
    "        zip_ref.extractall('data')\n",
    "        zip_ref.close()\n",
    "    else:\n",
    "        print(im_id[:-4] + ' was already uncompressed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing using SNAP\n",
    "The pre-processing workflow (to-be revised) is performed using SNAP Python API, snappy, and currently incudes the following steps:\n",
    "1. Apply orbit\n",
    "2. Speckle filtering\n",
    "3. Terrain correction\n",
    "4. Subset the area of interest\n",
    "5. Logaritmic transformation (to dB)\n",
    "6. Texture analysis\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snappy\n",
    "\n",
    "from sentinelsat.sentinel import read_geojson, geojson_to_wkt\n",
    "from snappy import ProductIO\n",
    "from snappy import HashMap\n",
    "import shutil\n",
    "import os  \n",
    "import ast\n",
    "\n",
    "from snappy import GPF\n",
    "\n",
    "GPF.getDefaultInstance().getOperatorSpiRegistry().loadOperatorSpis()\n",
    "HashMap = snappy.jpy.get_type('java.util.HashMap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Op name: org.esa.s1tbx.insar.gpf.coregistration.CreateStackOp\n",
      "Op alias: CreateStack\n",
      "\n",
      "PARAMETERS:\n",
      "\n",
      "masterBandNames: The list of source bands.\n",
      "Default Value: None\n",
      "\n",
      "slaveBandNames: The list of source bands.\n",
      "Default Value: None\n",
      "\n",
      "resamplingType: The method to be used when resampling the slave grid onto the master grid.\n",
      "Default Value: NONE\n",
      "\n",
      "extent: The output image extents.\n",
      "Default Value: Master\n",
      "\n",
      "initialOffsetMethod: Method to be used in computation of initial offset between master and slave\n",
      "Default Value: Orbit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Function to get help of the SNAP operators\n",
    "\n",
    "def Op_help(op):\n",
    "        op_spi = snappy.GPF.getDefaultInstance().getOperatorSpiRegistry().getOperatorSpi(op)\n",
    "        print('Op name: {}'.format(op_spi.getOperatorDescriptor().getName()))\n",
    "        print('Op alias: {}\\n'.format(op_spi.getOperatorDescriptor().getAlias()))\n",
    "        print('PARAMETERS:\\n')\n",
    "        param_Desc = op_spi.getOperatorDescriptor().getParameterDescriptors()\n",
    "        for param in param_Desc:\n",
    "            value_set = param_Desc[0].getValueSet()\n",
    "            if len(value_set) == 0:\n",
    "                print('{}: {}\\nDefault Value: {}\\n'.format(param.getName(),param.getDescription(),param.getDefaultValue()))\n",
    "            else:\n",
    "                print('{}: {}\\nDefault Value: {}\\nPossible param: {}\\n'.format(param.getName(),param.getDescription(),param.getDefaultValue(),list(value_set)))\n",
    "\n",
    "#Op_help(\"Multi-Temporal-Speckle-Filter\")\n",
    "Op_help(\"CreateStack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get a list of all Sentinel-1 toolbox operators\n",
    "op_spi = snappy.GPF.getDefaultInstance().getOperatorSpiRegistry().getOperatorSpis().toString()\n",
    "op_list = op_spi.split(', ')\n",
    "listname = []\n",
    "for op_str in op_list:\n",
    "    to_add = op_str\n",
    "    if op_str[0] == '[': to_add = op_str[1:]\n",
    "    elif op_str[-1] == ']': to_add = op_str[:-1]\n",
    "    #if to_add.split('.')[2] == 's1tbx':\n",
    "    listname.append(to_add.split('$')[0])\n",
    "listname.sort()\n",
    "#for name in listname:\n",
    "#    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and process S1 products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code reads directories in a folder containing only S1 products. Then, creates a dictionary using the products names as keys. Then, reads and stores diferent processing steps in a second-level dictionary (i.e. inside the first dictionary). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S1A_IW_GRDH_1SDV_20150916T231330.SAFE',\n",
       " 'S1A_IW_GRDH_1SDV_20151127T231327.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20150612T231317.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20150619T104249.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20150713T104249.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20150730T231319.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20150806T104250.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20150823T231320.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20150830T104252.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20151010T231322.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20151017T104253.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20151103T231321.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20151110T104241.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20151204T104300.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20151221T231315.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20160114T231328.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20160121T104259.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20160207T231327.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20160214T104258.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20160302T231327.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20160309T104258.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20160402T104259.SAFE',\n",
       " 'S1A_IW_GRDH_1SSV_20160419T231329.SAFE']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set a variable for the location of the data\n",
    "eo_direc = 'D:/eo_data/Saldana/'\n",
    "\n",
    "# Get the names of the downloaded files\n",
    "eo_files = os.listdir(eo_direc)\n",
    "list(eo_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dictionary to read Sentinel-1 L1 GRD products\n",
    "product = {}\n",
    "for element in eo_files:\n",
    "    product[element[:-5]] = {}\n",
    "\n",
    "# Define the area of interest\n",
    "WKTReader = snappy.jpy.get_type('com.vividsolutions.jts.io.WKTReader')\n",
    "regPath = \"//dapadfs/workspace_cluster_6/TRANSVERSAL_PROJECTS/MADR/COMPONENTE_2/Imagenes_Satelitales/Sentinel_2/\" + \\\n",
    "                      \"JSON_Saldana/saldanaextent.geojson\"\n",
    "geom = geojson_to_wkt(read_geojson(regPath))\n",
    "\n",
    "# Define polarizations of interest\n",
    "polarizations = ['VV', 'VH']\n",
    "\n",
    "# Final results dictionary, with lists\n",
    "results = []\n",
    "#for pol in polarizations:\n",
    "#    results[pol] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S1A_IW_GRDH_1SSV_20151017T104253',\n",
       " 'S1A_IW_GRDH_1SSV_20160419T231329',\n",
       " 'S1A_IW_GRDH_1SSV_20150612T231317',\n",
       " 'S1A_IW_GRDH_1SDV_20150916T231330',\n",
       " 'S1A_IW_GRDH_1SSV_20150806T104250',\n",
       " 'S1A_IW_GRDH_1SSV_20160309T104258',\n",
       " 'S1A_IW_GRDH_1SSV_20151221T231315',\n",
       " 'S1A_IW_GRDH_1SSV_20150823T231320',\n",
       " 'S1A_IW_GRDH_1SSV_20160121T104259',\n",
       " 'S1A_IW_GRDH_1SSV_20160207T231327',\n",
       " 'S1A_IW_GRDH_1SSV_20160214T104258',\n",
       " 'S1A_IW_GRDH_1SSV_20151204T104300',\n",
       " 'S1A_IW_GRDH_1SSV_20150619T104249',\n",
       " 'S1A_IW_GRDH_1SSV_20150730T231319',\n",
       " 'S1A_IW_GRDH_1SSV_20151110T104241',\n",
       " 'S1A_IW_GRDH_1SSV_20151010T231322',\n",
       " 'S1A_IW_GRDH_1SSV_20160402T104259',\n",
       " 'S1A_IW_GRDH_1SSV_20150830T104252',\n",
       " 'S1A_IW_GRDH_1SSV_20151103T231321',\n",
       " 'S1A_IW_GRDH_1SDV_20151127T231327',\n",
       " 'S1A_IW_GRDH_1SSV_20160302T231327',\n",
       " 'S1A_IW_GRDH_1SSV_20160114T231328',\n",
       " 'S1A_IW_GRDH_1SSV_20150713T104249']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading S1A_IW_GRDH_1SSV_20151017T104253\n",
      "Reading S1A_IW_GRDH_1SSV_20160419T231329\n",
      "Reading S1A_IW_GRDH_1SSV_20150612T231317\n",
      "Reading S1A_IW_GRDH_1SDV_20150916T231330\n",
      "Reading S1A_IW_GRDH_1SSV_20150806T104250\n",
      "Reading S1A_IW_GRDH_1SSV_20160309T104258\n",
      "Reading S1A_IW_GRDH_1SSV_20151221T231315\n",
      "Reading S1A_IW_GRDH_1SSV_20150823T231320\n",
      "Reading S1A_IW_GRDH_1SSV_20160121T104259\n",
      "Reading S1A_IW_GRDH_1SSV_20160207T231327\n",
      "Reading S1A_IW_GRDH_1SSV_20160214T104258\n",
      "Reading S1A_IW_GRDH_1SSV_20151204T104300\n",
      "Reading S1A_IW_GRDH_1SSV_20150619T104249\n",
      "Reading S1A_IW_GRDH_1SSV_20150730T231319\n",
      "Reading S1A_IW_GRDH_1SSV_20151110T104241\n",
      "Reading S1A_IW_GRDH_1SSV_20151010T231322\n",
      "Reading S1A_IW_GRDH_1SSV_20160402T104259\n",
      "Reading S1A_IW_GRDH_1SSV_20150830T104252\n",
      "Reading S1A_IW_GRDH_1SSV_20151103T231321\n",
      "Reading S1A_IW_GRDH_1SDV_20151127T231327\n",
      "Reading S1A_IW_GRDH_1SSV_20160302T231327\n",
      "Reading S1A_IW_GRDH_1SSV_20160114T231328\n",
      "Reading S1A_IW_GRDH_1SSV_20150713T104249\n"
     ]
    }
   ],
   "source": [
    "for key, value in product.iteritems():    \n",
    "    # Read the product\n",
    "    value['GRD'] = ProductIO.readProduct(eo_direc+key+'.SAFE/manifest.safe')\n",
    "    print('Reading '+key)\n",
    "    \n",
    "    # Apply orbit\n",
    "    param_orbit = HashMap()\n",
    "    value['orbit'] = GPF.createProduct(\"Apply-Orbit-File\", param_orbit, value['GRD'])\n",
    "    \n",
    "    # The following operations are specific por each polarization    \n",
    "    for pol in polarizations:\n",
    "        # Radiometric calibration\n",
    "        param_calibration = HashMap()\n",
    "        param_calibration.put('outputSigmaBand', True)\n",
    "        param_calibration.put('sourceBands', getBandNames(value['orbit'], 'Intensity_'+pol))\n",
    "        param_calibration.put('selectedPolarisations', pol)\n",
    "        param_calibration.put('outputImageScaleInDb', False)\n",
    "        value['calibration_'+pol] = GPF.createProduct(\"Calibration\", param_calibration, value['orbit'])\n",
    "        \n",
    "        # Terrain correction\n",
    "        param_terraincor = HashMap()\n",
    "        param_terraincor.put('demResamplingMethod', 'NEAREST_NEIGHBOUR')\n",
    "        param_terraincor.put('imgResamplingMethod', 'NEAREST_NEIGHBOUR')\n",
    "        param_terraincor.put('applyRadiometricNormalization', True)\n",
    "        param_terraincor.put('demName', 'SRTM 3Sec')\n",
    "        param_terraincor.put('pixelSpacingInMeter', 10.0)\n",
    "        param_terraincor.put('sourceBands', getBandNames(value['calibration_'+pol], 'Sigma0_'+pol))\n",
    "        param_terraincor.put('mapProjection', 'WGS84(DD)')\n",
    "        value['terraincor_'+pol] = GPF.createProduct(\"Terrain-Correction\", param_terraincor, value['calibration_'+pol])\n",
    "        \n",
    "        # Subset to area of interest\n",
    "        param_subset = HashMap()\n",
    "        param_subset.put('geoRegion', geom)\n",
    "        param_subset.put('outputImageScaleInDb', False)\n",
    "        param_subset.put('sourceBandNames', getBandNames(value['terraincor_'+pol], 'Sigma0_'+pol))\n",
    "        value['subset_'+pol] = GPF.createProduct(\"Subset\", param_subset, value['terraincor_'+pol])\n",
    "        \n",
    "        # define the name of the output\n",
    "        #output_name = eo_direc + 'prep/' + key + \"_\" + pol + \"_\"\n",
    "        \n",
    "        # Write the results to files\n",
    "        #ProductIO.writeProduct(value['subset_'+pol], output_name, 'BEAM-DIMAP')\n",
    "        results.append(value['subset_'+pol])#product\n",
    "        \n",
    "        # dispose all the intermediate products\n",
    "        #value['calibration_'+pol].dispose()\n",
    "        #value['terraincor_'+pol].dispose()\n",
    "        #value['subset_'+pol].dispose()\n",
    "        \n",
    "    #dispose all the intermediate products\n",
    "    #value['GRD'].dispose()\n",
    "    #value['orbit'].dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating stack...\n"
     ]
    }
   ],
   "source": [
    "stack = stacking(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-temporal speckle VV\n",
      "Sigma0_VV_mst_14Jan2016,Sigma0_VV_slv1_02Mar2016,Sigma0_VV_slv3_13Jul2015,Sigma0_VV_slv4_10Oct2015,Sigma0_VV_slv5_30Aug2015,Sigma0_VV_slv6_02Apr2016,Sigma0_VV_slv7_27Nov2015,Sigma0_VV_slv8_03Nov2015,Sigma0_VV_slv9_09Mar2016,Sigma0_VV_slv10_23Aug2015,Sigma0_VV_slv11_21Dec2015,Sigma0_VV_slv12_14Feb2016,Sigma0_VV_slv13_19Jun2015,Sigma0_VV_slv14_04Dec2015,Sigma0_VV_slv15_10Nov2015,Sigma0_VV_slv16_30Jul2015,Sigma0_VV_slv18_06Aug2015,Sigma0_VV_slv19_16Sep2015,Sigma0_VV_slv20_12Jun2015,Sigma0_VV_slv21_21Jan2016,Sigma0_VV_slv22_07Feb2016,Sigma0_VV_slv23_19Apr2016,Sigma0_VV_slv24_17Oct2015\n",
      "Multi-temporal speckle VH\n",
      "Sigma0_VH_slv2_27Nov2015,Sigma0_VH_slv17_16Sep2015\n"
     ]
    }
   ],
   "source": [
    "print('Multi-temporal speckle VV')\n",
    "speckle_VV = mtspeckle_sigma0(stack, 'VV')\n",
    "print(getBandNames(speckle_VV))\n",
    "\n",
    "print('Multi-temporal speckle VH')\n",
    "speckle_VH = mtspeckle_sigma0(stack, 'VH')\n",
    "print(getBandNames(speckle_VH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing VH\n",
      "Writing VV\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "java.lang.NullPointerException",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-6c4519e003ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mProductIO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteProduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSigma0_todB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeckle_VH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meo_direc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'VH_specklefil_dB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BEAM-DIMAP'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Writing VV'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mProductIO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteProduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSigma0_todB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeckle_VV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meo_direc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'VV_specklefil_dB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BEAM-DIMAP'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: java.lang.NullPointerException"
     ]
    }
   ],
   "source": [
    "print('Writing VH')\n",
    "ProductIO.writeProduct(Sigma0_todB(speckle_VH), eo_direc + 'VH_specklefil_dB', 'BEAM-DIMAP')\n",
    "print('Writing VV')\n",
    "ProductIO.writeProduct(Sigma0_todB(speckle_VV), eo_direc + 'VV_specklefil_dB', 'BEAM-DIMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in product.iteritems():\n",
    "    for pol in polarizations:\n",
    "        value['calibration_'+pol].dispose()\n",
    "        value['terraincor_'+pol].dispose()\n",
    "        value['subset_'+pol].dispose()\n",
    "    value['GRD'].dispose()\n",
    "    value['orbit'].dispose()\n",
    "stack.dispose()\n",
    "speckle_VV.dispose()\n",
    "speckle_VH.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speckle filtering \n",
    "\n",
    "* Multi-temporal speckle filtering\n",
    "* Scale transformation to dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read all the VV/VH files and store in a list (for further pre-processing)\n",
    "import os, re\n",
    "\n",
    "filenames_VV = filter(re.compile(r'VV_\\.dim').search, os.listdir(os.getcwd()+'\\data\\prep'))\n",
    "filenames_VH = filter(re.compile(r'VH_\\.dim').search, os.listdir(os.getcwd()+'\\data\\prep'))\n",
    "\n",
    "VV_l = []\n",
    "for eofile in pre_VV:\n",
    "    VV_l.append(ProductIO.readProduct(os.getcwd()+'/data/prep/' + eofile))\n",
    "\n",
    "VH_l = []\n",
    "for eofile in pre_VH:\n",
    "    VH_l.append(ProductIO.readProduct(os.getcwd()+'/data/prep/' + eofile))\n",
    "    \n",
    "## Apply multi-temporal speckle filtering\n",
    "sf_product_VV = mtspeckle_sigma0(VV_stack)\n",
    "sf_product_VH = mtspeckle_sigma0(VH_stack)\n",
    "\n",
    "# Change to logaritmic units (dB) \n",
    "db_product_VV = Sigma0_todB(sf_product_VV)\n",
    "db_product_VH = Sigma0_todB(sf_product_VH)\n",
    "\n",
    "## Write the results\n",
    "ProductIO.writeProduct(db_product_VV, eo_direc + 'prep/VH_specklefil_dB', 'BEAM-DIMAP')\n",
    "ProductIO.writeProduct(db_product_VH, eo_direc + 'prep/VH_specklefil_dB', 'BEAM-DIMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to apply multi-temporal speckle filter of a stacked product Sigma0 bands\n",
    "\"\"\"\n",
    "Multi-Temporal-Speckle-Filter Op Parameters:\n",
    "    filter: None --- Default Value: Lee Sigma\n",
    "    nfilterSizeX: The kernel x dimension --- Default Value: 3\n",
    "    nfilterSizeY: The kernel y dimension --- Default Value: 3\n",
    "    ndampingFactor: The damping factor (Frost filter only) --- Default Value: 2\n",
    "    nestimateENL: None --- Default Value: false\n",
    "    nenl: The number of looks --- Default Value: 1.0\n",
    "    nnumLooksStr: None --- nDefault Value: 1\n",
    "    nwindowSize: None --- Default Value: 7x7\n",
    "    ntargetWindowSizeStr: None --- Default Value: 3x3\n",
    "    nsigmaStr: None --- Default Value: 0.9\n",
    "    nanSize: The Adaptive Neighbourhood size --- Default Value: 50\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "def getBandNames (product, sfilter = ''):\n",
    "    \"\"\"\n",
    "    Produces a string to use in the sourceBandNames parameter specification of SNAP operators.\n",
    "    Args:\n",
    "        product (): \n",
    "        sfilter (string): regular expression to filter the name of the bands\n",
    "    Output:\n",
    "        returns a string with comma-separated band names\n",
    "    \"\"\"\n",
    "    band_names = product.getBandNames()\n",
    "    if sfilter != '':\n",
    "        band_names = filter(re.compile(r''+sfilter).search, band_names)\n",
    "    if len(band_names) > 0:\n",
    "        band_names = ','.join(band_names)\n",
    "    else:\n",
    "        band_names = None\n",
    "    return band_names\n",
    "\n",
    "def mtspeckle_sigma0 (stacked_prod, pol):\n",
    "    \"\"\"\n",
    "    Applies the a multi-temporal speckle filter to the a corregistered calibrated product stack. Takes the product bands\n",
    "    which name starts with 'Sigma0'.\n",
    "    \n",
    "    Args:\n",
    "        stacked_prod (): product with all the bands to be used for the multi-temporal speckle filter operation\n",
    "        pol (str): polarization to apply the speckle filter (VV or VH)\n",
    "    Output:\n",
    "    \"\"\"\n",
    "    param_specklefilter = HashMap()\n",
    "    param_specklefilter.put('sourceBandNames', getBandNames(stacked_prod, \"Sigma0_\"+pol))\n",
    "    param_specklefilter.put('filter', 'Lee Sigma')\n",
    "    sf_product = GPF.createProduct(\"Multi-Temporal-Speckle-Filter\", param_specklefilter, stacked_prod)\n",
    "    return sf_product\n",
    "\n",
    "def Sigma0_todB (product):\n",
    "    \"\"\"\n",
    "    Transforms the product bands to a logaritmic scale in dB (10*log10[band]).\n",
    "    \n",
    "    Args:\n",
    "        product: product with Sigma0 bands in linear units\n",
    "    Output:\n",
    "    \"\"\"\n",
    "    param_logdB = HashMap()\n",
    "    param_logdB.put('sourceBandNames', getBandNames(product))\n",
    "    db_product = GPF.createProduct(\"LinearToFromdB\", param_logdB, product)\n",
    "    return db_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that iterates over the list of products and stacks the its bands using the SNAP Collocate Operation\n",
    "\n",
    "def stacking(product_set):\n",
    "    # define the stack parameters\n",
    "    params = HashMap()\n",
    "    params.put('resamplingType', None)\n",
    "    params.put('initialOffsetMethod', 'Product Geolocation')\n",
    "    params.put('extent', 'Master')\n",
    "    \n",
    "    # create the stack\n",
    "    print(\"Creating stack...\")\n",
    "    create_stack = GPF.createProduct('CreateStack', params, product_set)\n",
    "    \n",
    "    return create_stack\n",
    "\n",
    "\n",
    "def stacking_ (prod_list):\n",
    "    \"\"\"\n",
    "    Recursive function. Takes a list of SNAP products and returns a stacked product with all the bands named with\n",
    "    the products acquisition dates.\n",
    "    Args:\n",
    "        prod_list: a list of products to be stacked\n",
    "    Output: returns an individual product with the bands of the other products \n",
    "    \"\"\"\n",
    "    if len(prod_list) == 1:\n",
    "        return prod_list[-1]\n",
    "    else:\n",
    "        param_coll = HashMap()\n",
    "        input_coll = HashMap()\n",
    "        input_coll.put(\"master\", prod_list[0])\n",
    "        input_coll.put(\"slave\", prod_list[1])\n",
    "        param_coll.put(\"masterComponentPattern\",\"${ORIGINAL_NAME}_\"+prod_list[0].getName()[17:31])\n",
    "        param_coll.put(\"slaveComponentPattern\",\"${ORIGINAL_NAME}_\"+prod_list[1].getName()[17:31])\n",
    "        prod_list[1] = GPF.createProduct('Collocate', param_coll, input_coll)\n",
    "        return stacking_(prod_list[1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texture analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# paramaters for GLCM texture analysis\n",
    "paramGLCM = HashMap()\n",
    "paramGLCM.put('sourceBandNames', 'Sigma0_' + 'VV')\n",
    "paramGLCM.put('windowSizeStr', '5x5')\n",
    "paramGLCM.put('quantizerStr', 'Probabilistic Quantizer')\n",
    "paramGLCM.put('quantizationLevelsStr', '16')\n",
    "paramGLCM.put('displacement','4' )\n",
    "paramGLCM.put('outputContrast','true')\n",
    "paramGLCM.put('outputDissimilarity','true')\n",
    "paramGLCM.put('outputHomogeneity','true')\n",
    "paramGLCM.put('outputASM','true')\n",
    "paramGLCM.put('outputEnergy','true')\n",
    "paramGLCM.put('outputMean','true')\n",
    "paramGLCM.put('outputVariance','true')\n",
    "paramGLCM.put('outputCorrelation','true')\n",
    "\n",
    "product = GPF.createProduct(\"GLCM\", paramGLCM, product)\n",
    "\n",
    "#GLCM_output = \"C:/Users/asalazar/Documents/Ibague/_subset_VV\"\n",
    "\n",
    "#ProductIO.writeProduct(targetGCLM, GLCM_output, 'BEAM-DIMAP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor function. Could be useful for monitoring progress of file writing. To test!\n",
    "\n",
    "from snappy import jpy\n",
    "\n",
    "def createProgressMonitor():\n",
    "    PWPM = jpy.get_type('com.bc.ceres.core.PrintWriterProgressMonitor')\n",
    "    JavaSystem = jpy.get_type('java.lang.System')\n",
    "    monitor = PWPM(JavaSystem.out)\n",
    "    return monitor\n",
    "\n",
    "ProductIO.writeProduct(product, 'C:/Users/asalazar/Documents/Ibague/GLCM_output', 'BEAM-DIMAP', pm = createProgressMonitor())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
